{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06d76302-b3ba-4c0a-8217-bd8c10a68fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8590e716-edca-48d2-be98-203d487b116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, ExtraTreesClassifier, ExtraTreesRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_absolute_error\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bb855af-9e3d-4b0a-b5d3-8ef3fb0cc472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    train_path = './data/train.csv'\n",
    "    test_path = './data/test.csv'\n",
    "    \n",
    "    if not os.path.exists(train_path) or not os.path.exists(test_path):\n",
    "        raise FileNotFoundError(f\"Data files not found. Please check paths.\")\n",
    "    \n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    \n",
    "    print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n",
    "    print(f\"Train columns: {train_df.columns.tolist()}\")\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "618f6df8-4db7-41a7-90f1-5bcafcd4816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numeric_columns(df):\n",
    "    numeric_cols = ['invoiceTotal', 'QtyShipped', 'ExtendedQuantity', 'PriceUOM', \n",
    "                   'UnitPrice', 'ExtendedPrice', 'REVISED_ESTIMATE']\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).str.replace(r'[$,]', '', regex=True)\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7176861c-8289-4442-8ffb-f8a6006bc128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date_features(df):\n",
    "    date_cols = ['invoiceDate', 'CONSTRUCTION_START_DATE', 'SUBSTANTIAL_COMPLETION_DATE']\n",
    "    \n",
    "    for col in date_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "            \n",
    "            df[f'{col}_year'] = df[col].dt.year.fillna(0).astype(int)\n",
    "            df[f'{col}_month'] = df[col].dt.month.fillna(0).astype(int)\n",
    "            df[f'{col}_day'] = df[col].dt.day.fillna(0).astype(int)\n",
    "            df[f'{col}_weekday'] = df[col].dt.weekday.fillna(0).astype(int)\n",
    "            df[f'{col}_quarter'] = df[col].dt.quarter.fillna(0).astype(int)\n",
    "    \n",
    "    if 'CONSTRUCTION_START_DATE' in df.columns and 'SUBSTANTIAL_COMPLETION_DATE' in df.columns:\n",
    "        duration = (df['SUBSTANTIAL_COMPLETION_DATE'] - df['CONSTRUCTION_START_DATE']).dt.days\n",
    "        df['project_duration_days'] = duration.fillna(0).astype(float)\n",
    "    \n",
    "    for col in date_cols:\n",
    "        if col in df.columns:\n",
    "            df = df.drop(columns=[col])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5481d061-d722-40a1-ac56-dfb6dc1036fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df, is_train=True):\n",
    "    \"\"\"Engineer features from project metadata.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    df = clean_numeric_columns(df)\n",
    "    \n",
    "    df = extract_date_features(df)\n",
    "    \n",
    "    df['rooms_per_floor'] = df['NUMROOMS'] / (df['NUMFLOORS'] + 1)  \n",
    "    df['beds_per_room'] = df['NUMBEDS'] / (df['NUMROOMS'] + 1)\n",
    "    df['size_per_floor'] = df['SIZE_BUILDINGSIZE'] / (df['NUMFLOORS'] + 1)\n",
    "    df['mw_per_sqft'] = df['MW'] / (df['SIZE_BUILDINGSIZE'] + 1)\n",
    "    \n",
    "    df['is_large_project'] = (df['SIZE_BUILDINGSIZE'] > df['SIZE_BUILDINGSIZE'].median()).astype(int)\n",
    "    df['is_high_capacity'] = (df['MW'] > df['MW'].median()).astype(int)\n",
    "    df['is_multi_floor'] = (df['NUMFLOORS'] > 1).astype(int)\n",
    "    \n",
    "    complexity_mapping = {\n",
    "        'Workspace': 1, 'Health Center': 2, 'Learning Hub': 2, \n",
    "        'Ambulatory Care': 3, 'Critical Ops': 4, 'R&D Laboratories': 4,\n",
    "        'Hospitality Hall': 3, 'Misc Build': 2, 'Pharma Synth': 4, \n",
    "        'Data Center': 5, 'Logistics Hub': 2, 'Smart Fabrication': 2, \n",
    "        'Commerce Space': 1\n",
    "    }\n",
    "    \n",
    "    market_importance = {\n",
    "        'Enterprise': 3, 'Future Tech': 4, 'Bio Innovation': 4,\n",
    "        'Wellness': 2, 'Tertiary Learning': 2, 'Misc Market': 1\n",
    "    }\n",
    "    \n",
    "    economic_tiers = {\n",
    "        'Maharashtra': 3, 'Gujarat': 3, 'Karnataka': 3, 'Tamil Nadu': 3,\n",
    "        'Rajasthan': 2, 'Uttar Pradesh': 2, 'Madhya Pradesh': 2,\n",
    "        'West Bengal': 2, 'Kerala': 2, 'Punjab': 2\n",
    "    }\n",
    "    df['state_economic_tier'] = df['STATE'].map(economic_tiers).fillna(1)\n",
    "    \n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "    \n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    df[categorical_cols] = df[categorical_cols].fillna('Unknown')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dd1894b-0532-4807-b37d-04538a4daf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(train_df, test_df):\n",
    "    \"\"\"Prepare feature matrices for training.\"\"\"\n",
    "    \n",
    "    if 'MasterItemNo' in train_df.columns and 'QtyShipped' in train_df.columns:\n",
    "        y_class_raw = train_df['MasterItemNo'].fillna('Unknown').astype(str)\n",
    "        y_reg_raw = train_df['QtyShipped']\n",
    "        \n",
    "        class_counts = y_class_raw.value_counts()\n",
    "        min_samples = 5 \n",
    "        frequent_classes = class_counts[class_counts >= min_samples].index.tolist()\n",
    "        \n",
    "        y_class_grouped = y_class_raw.copy()\n",
    "        y_class_grouped[~y_class_grouped.isin(frequent_classes)] = 'OTHER_RARE'\n",
    "        \n",
    "        target_encoder = LabelEncoder()\n",
    "        y_class = target_encoder.fit_transform(y_class_grouped)\n",
    "        \n",
    "        if y_reg_raw.dtype == 'object':\n",
    "            y_reg_raw = pd.to_numeric(y_reg_raw.astype(str).str.replace(r'[^0-9.]', '', regex=True), errors='coerce')\n",
    "        y_reg = y_reg_raw.fillna(y_reg_raw.median()).values\n",
    "        \n",
    "        print(f\"Target encoding - Classes: {len(target_encoder.classes_)} (reduced from {len(class_counts)})\")\n",
    "        print(f\"Frequent classes: {len(frequent_classes)}, Rare classes grouped: {len(class_counts) - len(frequent_classes)}\")\n",
    "        print(f\"QtyShipped range: {y_reg.min():.2f} to {y_reg.max():.2f}\")\n",
    "        \n",
    "        class_mapping = {'encoder': target_encoder, 'original_classes': y_class_raw.values}\n",
    "        \n",
    "        feature_cols = [col for col in train_df.columns if col not in ['MasterItemNo', 'QtyShipped', 'id']]\n",
    "    else:\n",
    "        y_class, y_reg, class_mapping = None, None, None\n",
    "        feature_cols = [col for col in train_df.columns if col not in ['id']]\n",
    "    \n",
    "    common_cols = [col for col in feature_cols if col in test_df.columns]\n",
    "    \n",
    "    X_train = train_df[common_cols].copy()\n",
    "    X_test = test_df[common_cols].copy()\n",
    "    \n",
    "    X_train = engineer_features(X_train, is_train=True)\n",
    "    X_test = engineer_features(X_test, is_train=False)\n",
    "    \n",
    "    common_engineered_cols = [col for col in X_train.columns if col in X_test.columns]\n",
    "    X_train = X_train[common_engineered_cols]\n",
    "    X_test = X_test[common_engineered_cols]\n",
    "    \n",
    "    for col in X_train.columns:\n",
    "        if X_train[col].dtype == 'object':\n",
    "            X_train[col] = pd.to_numeric(X_train[col], errors='coerce')\n",
    "            X_test[col] = pd.to_numeric(X_test[col], errors='coerce')\n",
    "            \n",
    "            if X_train[col].dtype == 'object':\n",
    "                le = LabelEncoder()\n",
    "                combined_values = pd.concat([X_train[col], X_test[col]]).astype(str).fillna('Unknown')\n",
    "                le.fit(combined_values)\n",
    "                \n",
    "                X_train[col] = le.transform(X_train[col].astype(str).fillna('Unknown'))\n",
    "                X_test[col] = le.transform(X_test[col].astype(str).fillna('Unknown'))\n",
    "    \n",
    "    X_train = X_train.fillna(0)\n",
    "    X_test = X_test.fillna(0)\n",
    "    \n",
    "    for col in X_train.columns:\n",
    "        X_train[col] = pd.to_numeric(X_train[col], errors='coerce').fillna(0)\n",
    "        X_test[col] = pd.to_numeric(X_test[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train.values)\n",
    "    X_test_scaled = scaler.transform(X_test.values)\n",
    "    \n",
    "    feature_sets = {\n",
    "        'original': (X_train.values, X_test.values),\n",
    "        'scaled': (X_train_scaled, X_test_scaled),\n",
    "    }\n",
    "    \n",
    "    print(f\"Feature matrix shape: {X_train_scaled.shape}\")\n",
    "    print(f\"Final feature columns: {len(X_train.columns)}\")\n",
    "    \n",
    "    return feature_sets, y_class, y_reg, X_train.columns.tolist(), class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5682cdbd-ef26-4105-a13c-93983a41328f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading data...\n",
      "Train shape: (14036, 26), Test shape: (2685, 24)\n",
      "Train columns: ['id', 'PROJECTNUMBER', 'MW', 'PROJECT_CITY', 'STATE', 'PROJECT_COUNTRY', 'CORE_MARKET', 'PROJECT_TYPE', 'SIZE_BUILDINGSIZE', 'NUMFLOORS', 'NUMROOMS', 'NUMBEDS', 'invoiceId', 'invoiceDate', 'invoiceTotal', 'ItemDescription', 'MasterItemNo', 'QtyShipped', 'UOM', 'ExtendedQuantity', 'PriceUOM', 'UnitPrice', 'ExtendedPrice', 'CONSTRUCTION_START_DATE', 'SUBSTANTIAL_COMPLETION_DATE', 'REVISED_ESTIMATE']\n",
      "\n",
      "2. Engineering features...\n",
      "Target encoding - Classes: 504 (reduced from 2572)\n",
      "Frequent classes: 503, Rare classes grouped: 2069\n",
      "QtyShipped range: 0.00 to 2100200.00\n",
      "Feature matrix shape: (14036, 44)\n",
      "Final feature columns: 44\n",
      "\n",
      "3. Creating base models...\n",
      "Created 1 classification and 1 regression models.\n",
      "\n",
      "4. Training and evaluating models...\n",
      "\n",
      "============================================================\n",
      "EVALUATING BASE MODELS WITH 5-FOLD CROSS-VALIDATION\n",
      "============================================================\n",
      "\n",
      "Classification Model:\n",
      "----------------------------------------\n",
      "RandomForest_Clf          | Accuracy: 0.4452 ± 0.0060 | F1: 0.3375 ± 0.0063\n",
      "\n",
      "Regression Model:\n",
      "----------------------------------------\n",
      "LinearRegression_Reg      | MAE: 1302.6182 ± 315.1000 | Reg Score: 0.9994\n",
      "\n",
      "5. Saving training results...\n",
      "Results saved to 'training_outputs' directory.\n",
      "1. Loading training results...\n",
      "Training results loaded successfully.\n",
      "\n",
      "2. Creating ensemble predictions...\n",
      "\n",
      "Evaluating ensemble methods...\n",
      "Simple Ensemble | Composite: 0.6960 | Acc: 0.4452 | F1: 0.3402 | Reg: 0.9994\n",
      "Weighted Ensemble | Composite: 0.6960 | Acc: 0.4452 | F1: 0.3402 | Reg: 0.9994\n",
      "Best Individual | Composite: 0.6960 | Acc: 0.4452 | F1: 0.3402 | Reg: 0.9994\n",
      "  (Classification: RandomForest_Clf, Regression: LinearRegression_Reg)\n",
      "\n",
      "3. Saving ensemble submissions...\n",
      "\n",
      "Ensemble method rankings:\n",
      "1. simple_ensemble      | Composite Score: 0.6960\n",
      "2. weighted_ensemble    | Composite Score: 0.6960\n",
      "3. best_individual      | Composite Score: 0.6960\n",
      "Saved: ensemble_submission_1_simple_ensemble.csv\n",
      "  - MasterItemNo samples: ['61289' '61289' '61289' '61289' '61289']\n",
      "  - QtyShipped range: 0.00 to 76064.75\n",
      "Saved: ensemble_submission_2_weighted_ensemble.csv\n",
      "  - MasterItemNo samples: ['61289' '61289' '61289' '61289' '61289']\n",
      "  - QtyShipped range: 0.00 to 76064.75\n",
      "Saved: ensemble_submission_3_best_individual.csv\n",
      "  - MasterItemNo samples: ['61289' '61289' '61289' '61289' '61289']\n",
      "  - QtyShipped range: 0.00 to 76064.75\n",
      "\n",
      "Creating weighted final submission...\n",
      "Final submission created!\n",
      "Shape: (2685, 3)\n",
      "MasterItemNo unique values: 58\n",
      "QtyShipped range: 2.10 to 38082.92\n",
      "\n",
      "Submission preview:\n",
      "      id MasterItemNo   QtyShipped\n",
      "0   3708        61289    20.498186\n",
      "1   6302        61289    87.617217\n",
      "2   8687        61289    18.436340\n",
      "3    361        61289    71.314391\n",
      "4  13231        61289  2164.267719\n",
      "5   9001        61289  1384.212161\n",
      "6   1924        61289  1012.230829\n",
      "7   8950        61289    17.910822\n",
      "8   4449        61289   537.188537\n",
      "9   1954        61289   933.539967\n",
      "Final submission saved as 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "def create_base_models():\n",
    "    \n",
    "    clf_models = [\n",
    "        {\n",
    "            'name': 'RandomForest_Clf',\n",
    "            'model': RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=10, random_state=42, n_jobs=-1),\n",
    "            'feature_set': 'original'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    reg_models = [\n",
    "        {\n",
    "            'name': 'LinearRegression_Reg',\n",
    "            'model': LinearRegression(),\n",
    "            'feature_set': 'scaled'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return clf_models, reg_models\n",
    "\n",
    "def evaluate_models(clf_models, reg_models, feature_sets, y_class, y_reg):\n",
    "    \"\"\"Evaluate models with cross-validation.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EVALUATING BASE MODELS WITH 5-FOLD CROSS-VALIDATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    clf_predictions = {}\n",
    "    reg_predictions = {}\n",
    "    clf_cv_preds = {}\n",
    "    reg_cv_preds = {}\n",
    "    model_scores = []\n",
    "    \n",
    "    print(\"\\nClassification Model:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for model_config in clf_models:\n",
    "        model_name = model_config['name']\n",
    "        model = model_config['model']\n",
    "        feature_set_name = model_config['feature_set']\n",
    "        \n",
    "        X_train, X_test = feature_sets[feature_set_name]\n",
    "        \n",
    "        cv_scores_acc = []\n",
    "        cv_scores_f1 = []\n",
    "        cv_preds = np.zeros(len(y_class))\n",
    "        \n",
    "        for train_idx, val_idx in kf.split(X_train):\n",
    "            X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "            y_tr, y_val = y_class[train_idx], y_class[val_idx]\n",
    "            \n",
    "            try:\n",
    "                model.fit(X_tr, y_tr)\n",
    "                y_pred = model.predict(X_val)\n",
    "                \n",
    "                acc = accuracy_score(y_val, y_pred)\n",
    "                f1 = f1_score(y_val, y_pred, average='weighted', zero_division=0)\n",
    "                \n",
    "                cv_scores_acc.append(acc)\n",
    "                cv_scores_f1.append(f1)\n",
    "                cv_preds[val_idx] = y_pred\n",
    "            except Exception as e:\n",
    "                print(f\"Error in {model_name}: {e}\")\n",
    "                cv_scores_acc.append(0)\n",
    "                cv_scores_f1.append(0)\n",
    "                cv_preds[val_idx] = 0\n",
    "        \n",
    "        avg_acc = np.mean(cv_scores_acc)\n",
    "        avg_f1 = np.mean(cv_scores_f1)\n",
    "        \n",
    "        print(f\"{model_name:<25} | Accuracy: {avg_acc:.4f} ± {np.std(cv_scores_acc):.4f} | F1: {avg_f1:.4f} ± {np.std(cv_scores_f1):.4f}\")\n",
    "        \n",
    "        try:\n",
    "            model.fit(X_train, y_class)\n",
    "            test_pred = model.predict(X_test)\n",
    "        except Exception as e:\n",
    "            print(f\"Error training {model_name} on full data: {e}\")\n",
    "            test_pred = np.zeros(X_test.shape[0])\n",
    "        \n",
    "        clf_predictions[model_name] = test_pred\n",
    "        clf_cv_preds[model_name] = cv_preds\n",
    "        \n",
    "        model_scores.append({\n",
    "            'model': model_name,\n",
    "            'type': 'classification',\n",
    "            'accuracy': avg_acc,\n",
    "            'f1': avg_f1\n",
    "        })\n",
    "    \n",
    "    print(\"\\nRegression Model:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for model_config in reg_models:\n",
    "        model_name = model_config['name'] \n",
    "        model = model_config['model']\n",
    "        feature_set_name = model_config['feature_set']\n",
    "        \n",
    "        X_train, X_test = feature_sets[feature_set_name]\n",
    "        \n",
    "        cv_scores_mae = []\n",
    "        cv_preds = np.zeros(len(y_reg))\n",
    "        \n",
    "        for train_idx, val_idx in kf.split(X_train):\n",
    "            X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "            y_tr, y_val = y_reg[train_idx], y_reg[val_idx]\n",
    "            \n",
    "            try:\n",
    "                model.fit(X_tr, y_tr)\n",
    "                y_pred = model.predict(X_val)\n",
    "                \n",
    "                mae = mean_absolute_error(y_val, y_pred)\n",
    "                cv_scores_mae.append(mae)\n",
    "                cv_preds[val_idx] = y_pred\n",
    "            except Exception as e:\n",
    "                print(f\"Error in {model_name}: {e}\")\n",
    "                cv_scores_mae.append(y_reg.std())\n",
    "                cv_preds[val_idx] = y_reg.mean()\n",
    "        \n",
    "        avg_mae = np.mean(cv_scores_mae)\n",
    "        \n",
    "        mae_range = y_reg.max() - y_reg.min()\n",
    "        norm_mae = avg_mae / mae_range if mae_range > 0 else 0\n",
    "        reg_score = max(0, 1 - norm_mae)\n",
    "        \n",
    "        print(f\"{model_name:<25} | MAE: {avg_mae:.4f} ± {np.std(cv_scores_mae):.4f} | Reg Score: {reg_score:.4f}\")\n",
    "        \n",
    "        try:\n",
    "            model.fit(X_train, y_reg)\n",
    "            test_pred = model.predict(X_test)\n",
    "            test_pred = np.maximum(test_pred, 0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error training {model_name} on full data: {e}\")\n",
    "            test_pred = np.full(X_test.shape[0], y_reg.mean())\n",
    "        \n",
    "        reg_predictions[model_name] = test_pred\n",
    "        reg_cv_preds[model_name] = cv_preds\n",
    "        \n",
    "        model_scores.append({\n",
    "            'model': model_name,\n",
    "            'type': 'regression', \n",
    "            'mae': avg_mae,\n",
    "            'reg_score': reg_score\n",
    "        })\n",
    "    \n",
    "    return clf_predictions, reg_predictions, clf_cv_preds, reg_cv_preds, model_scores, y_class, y_reg\n",
    "\n",
    "def main_train():\n",
    "    \"\"\"Main training pipeline.\"\"\"\n",
    "    try:\n",
    "        print(\"1. Loading data...\")\n",
    "        train_df, test_df = load_and_preprocess_data()\n",
    "        \n",
    "        print(\"\\n2. Engineering features...\")\n",
    "        feature_sets, y_class, y_reg, feature_names, class_mapping = prepare_features(train_df, test_df)\n",
    "        \n",
    "        print(\"\\n3. Creating base models...\")\n",
    "        clf_models, reg_models = create_base_models()\n",
    "        print(f\"Created {len(clf_models)} classification and {len(reg_models)} regression models.\")\n",
    "        \n",
    "        print(\"\\n4. Training and evaluating models...\")\n",
    "        clf_preds, reg_preds, clf_cv_preds, reg_cv_preds, model_scores, y_class, y_reg = evaluate_models(\n",
    "            clf_models, reg_models, feature_sets, y_class, y_reg\n",
    "        )\n",
    "        \n",
    "        print(\"\\n5. Saving training results...\")\n",
    "        output_dir = \"training_outputs\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        joblib.dump(clf_preds, os.path.join(output_dir, 'clf_predictions.joblib'))\n",
    "        joblib.dump(reg_preds, os.path.join(output_dir, 'reg_predictions.joblib'))\n",
    "        joblib.dump(clf_cv_preds, os.path.join(output_dir, 'clf_cv_preds.joblib'))\n",
    "        joblib.dump(reg_cv_preds, os.path.join(output_dir, 'reg_cv_preds.joblib'))\n",
    "        joblib.dump(model_scores, os.path.join(output_dir, 'model_scores.joblib'))\n",
    "        joblib.dump(y_class, os.path.join(output_dir, 'y_class.joblib'))\n",
    "        joblib.dump(y_reg, os.path.join(output_dir, 'y_reg.joblib'))\n",
    "        joblib.dump(test_df['id'].values, os.path.join(output_dir, 'test_ids.joblib'))\n",
    "        joblib.dump(class_mapping, os.path.join(output_dir, 'class_mapping.joblib'))\n",
    "        \n",
    "        print(f\"Results saved to '{output_dir}' directory.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in training pipeline: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def composite_score(y_true_class, y_pred_class, y_true_reg, y_pred_reg):\n",
    "    \"\"\"Calculate the composite score as per competition rules.\"\"\"\n",
    "    acc = accuracy_score(y_true_class, y_pred_class)\n",
    "    f1 = f1_score(y_true_class, y_pred_class, average='weighted', zero_division=0)\n",
    "    \n",
    "    mae = mean_absolute_error(y_true_reg, y_pred_reg)\n",
    "    reg_range = y_true_reg.max() - y_true_reg.min() if y_true_reg.max() != y_true_reg.min() else 1\n",
    "    norm_mae = mae / reg_range\n",
    "    reg_score = max(0, 1 - norm_mae)\n",
    "    \n",
    "    composite = 0.25 * acc + 0.25 * f1 + 0.5 * reg_score\n",
    "    \n",
    "    return composite, acc, f1, reg_score\n",
    "\n",
    "def create_ensemble_predictions(clf_preds, reg_preds, clf_cv_preds, reg_cv_preds, y_class, y_reg):\n",
    "    \n",
    "    from scipy import stats\n",
    "    \n",
    "    ensemble_methods = {}\n",
    "    \n",
    "    print(\"\\nEvaluating ensemble methods...\")\n",
    "    \n",
    "    clf_names = list(clf_preds.keys())\n",
    "    reg_names = list(reg_preds.keys())\n",
    "    \n",
    "    clf_ensemble_cv = np.zeros(len(y_class))\n",
    "    clf_ensemble_test = np.zeros(len(list(clf_preds.values())[0]))\n",
    "    \n",
    "    for i in range(len(y_class)):\n",
    "        votes = [clf_cv_preds[name][i] for name in clf_names]\n",
    "        clf_ensemble_cv[i] = stats.mode(votes, keepdims=True)[0][0]\n",
    "    \n",
    "    for i in range(len(list(clf_preds.values())[0])):\n",
    "        votes = [clf_preds[name][i] for name in clf_names]\n",
    "        clf_ensemble_test[i] = stats.mode(votes, keepdims=True)[0][0]\n",
    "    \n",
    "    reg_ensemble_cv = np.mean([reg_cv_preds[name] for name in reg_names], axis=0)\n",
    "    reg_ensemble_test = np.mean([reg_preds[name] for name in reg_names], axis=0)\n",
    "    \n",
    "    composite, acc, f1, reg_score = composite_score(y_class, clf_ensemble_cv, y_reg, reg_ensemble_cv)\n",
    "    \n",
    "    ensemble_methods['simple_ensemble'] = {\n",
    "        'clf_test': clf_ensemble_test,\n",
    "        'reg_test': reg_ensemble_test,\n",
    "        'cv_score': composite,\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'reg_score': reg_score\n",
    "    }\n",
    "    \n",
    "    print(f\"Simple Ensemble | Composite: {composite:.4f} | Acc: {acc:.4f} | F1: {f1:.4f} | Reg: {reg_score:.4f}\")\n",
    "    \n",
    "    from collections import defaultdict\n",
    "    model_performance = defaultdict(dict)\n",
    "    \n",
    "    for clf_name in clf_names:\n",
    "        clf_cv = clf_cv_preds[clf_name] \n",
    "        acc_cv = accuracy_score(y_class, clf_cv)\n",
    "        f1_cv = f1_score(y_class, clf_cv, average='weighted', zero_division=0)\n",
    "        model_performance[clf_name]['acc'] = acc_cv\n",
    "        model_performance[clf_name]['f1'] = f1_cv\n",
    "        model_performance[clf_name]['clf_weight'] = (acc_cv + f1_cv) / 2\n",
    "    \n",
    "    for reg_name in reg_names:\n",
    "        reg_cv = reg_cv_preds[reg_name]\n",
    "        mae_cv = mean_absolute_error(y_reg, reg_cv)\n",
    "        reg_range = y_reg.max() - y_reg.min() if y_reg.max() != y_reg.min() else 1\n",
    "        reg_score_cv = max(0, 1 - mae_cv/reg_range) \n",
    "        model_performance[reg_name]['reg_score'] = reg_score_cv\n",
    "        model_performance[reg_name]['reg_weight'] = reg_score_cv\n",
    "    \n",
    "    clf_weighted_cv = clf_ensemble_cv.copy()\n",
    "    clf_weighted_test = clf_ensemble_test.copy()\n",
    "    \n",
    "    reg_weights = np.array([model_performance[name]['reg_weight'] for name in reg_names])\n",
    "    reg_weights = reg_weights / reg_weights.sum() if reg_weights.sum() > 0 else np.ones(len(reg_names)) / len(reg_names)\n",
    "    \n",
    "    reg_weighted_cv = np.average([reg_cv_preds[name] for name in reg_names], axis=0, weights=reg_weights)\n",
    "    reg_weighted_test = np.average([reg_preds[name] for name in reg_names], axis=0, weights=reg_weights)\n",
    "    \n",
    "    composite, acc, f1, reg_score = composite_score(y_class, clf_weighted_cv, y_reg, reg_weighted_cv)\n",
    "    \n",
    "    ensemble_methods['weighted_ensemble'] = {\n",
    "        'clf_test': clf_weighted_test,\n",
    "        'reg_test': reg_weighted_test,\n",
    "        'cv_score': composite,\n",
    "        'accuracy': acc, \n",
    "        'f1': f1,\n",
    "        'reg_score': reg_score\n",
    "    }\n",
    "    \n",
    "    print(f\"Weighted Ensemble | Composite: {composite:.4f} | Acc: {acc:.4f} | F1: {f1:.4f} | Reg: {reg_score:.4f}\")\n",
    "    \n",
    "    best_clf_name = max(clf_names, key=lambda x: model_performance[x]['clf_weight'])\n",
    "    best_reg_name = max(reg_names, key=lambda x: model_performance[x]['reg_weight'])\n",
    "    \n",
    "    composite, acc, f1, reg_score = composite_score(\n",
    "        y_class, clf_cv_preds[best_clf_name], \n",
    "        y_reg, reg_cv_preds[best_reg_name]\n",
    "    )\n",
    "    \n",
    "    ensemble_methods['best_individual'] = {\n",
    "        'clf_test': clf_preds[best_clf_name],\n",
    "        'reg_test': reg_preds[best_reg_name], \n",
    "        'cv_score': composite,\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'reg_score': reg_score\n",
    "    }\n",
    "    \n",
    "    print(f\"Best Individual | Composite: {composite:.4f} | Acc: {acc:.4f} | F1: {f1:.4f} | Reg: {reg_score:.4f}\")\n",
    "    print(f\"  (Classification: {best_clf_name}, Regression: {best_reg_name})\")\n",
    "    \n",
    "    return ensemble_methods\n",
    "\n",
    "def decode_predictions(encoded_preds, class_mapping):\n",
    "    encoder = class_mapping['encoder']\n",
    "    original_classes = class_mapping['original_classes']\n",
    "    \n",
    "    decoded_grouped = encoder.inverse_transform(encoded_preds.astype(int))\n",
    "\n",
    "    most_frequent_class = pd.Series(original_classes).value_counts().index[0]\n",
    "    decoded_final = np.where(decoded_grouped == 'OTHER_RARE', most_frequent_class, decoded_grouped)\n",
    "    \n",
    "    return decoded_final\n",
    "\n",
    "def save_ensemble_submissions(ensemble_methods, test_ids, class_mapping):\n",
    "    \"\"\"Save ensemble submissions.\"\"\"\n",
    "    \n",
    "    sorted_methods = sorted(ensemble_methods.items(), key=lambda x: x[1]['cv_score'], reverse=True)\n",
    "    \n",
    "    print(\"\\nEnsemble method rankings:\")\n",
    "    for i, (method_name, method_data) in enumerate(sorted_methods, 1):\n",
    "        score = method_data['cv_score']\n",
    "        print(f\"{i}. {method_name:<20} | Composite Score: {score:.4f}\")\n",
    "    \n",
    "    for rank, (method_name, method_data) in enumerate(sorted_methods[:3], 1):\n",
    "        clf_pred_encoded = method_data['clf_test'].astype(int)\n",
    "        reg_pred = np.maximum(method_data['reg_test'], 0) \n",
    "        \n",
    "        clf_pred_original = decode_predictions(clf_pred_encoded, class_mapping)\n",
    "        \n",
    "        submission_df = pd.DataFrame({\n",
    "            'id': test_ids,\n",
    "            'MasterItemNo': clf_pred_original,\n",
    "            'QtyShipped': reg_pred\n",
    "        })\n",
    "        \n",
    "        filename = f'ensemble_submission_{rank}_{method_name}.csv'\n",
    "        submission_df.to_csv(filename, index=False)\n",
    "        \n",
    "        print(f\"Saved: {filename}\")\n",
    "        print(f\"  - MasterItemNo samples: {clf_pred_original[:5]}\")\n",
    "        print(f\"  - QtyShipped range: {reg_pred.min():.2f} to {reg_pred.max():.2f}\")\n",
    "\n",
    "def main_ensemble():\n",
    "    \"\"\"Main ensembling pipeline.\"\"\"\n",
    "   \n",
    "    input_dir = \"training_outputs\"\n",
    "    \n",
    "    try:\n",
    "        print(\"1. Loading training results...\")\n",
    "        clf_preds = joblib.load(os.path.join(input_dir, 'clf_predictions.joblib'))\n",
    "        reg_preds = joblib.load(os.path.join(input_dir, 'reg_predictions.joblib'))\n",
    "        clf_cv_preds = joblib.load(os.path.join(input_dir, 'clf_cv_preds.joblib'))\n",
    "        reg_cv_preds = joblib.load(os.path.join(input_dir, 'reg_cv_preds.joblib'))\n",
    "        y_class = joblib.load(os.path.join(input_dir, 'y_class.joblib'))\n",
    "        y_reg = joblib.load(os.path.join(input_dir, 'y_reg.joblib'))\n",
    "        test_ids = joblib.load(os.path.join(input_dir, 'test_ids.joblib'))\n",
    "        class_mapping = joblib.load(os.path.join(input_dir, 'class_mapping.joblib'))\n",
    "        \n",
    "        print(\"Training results loaded successfully.\")\n",
    "        \n",
    "        print(\"\\n2. Creating ensemble predictions...\")\n",
    "        ensemble_methods = create_ensemble_predictions(\n",
    "            clf_preds, reg_preds, clf_cv_preds, reg_cv_preds, y_class, y_reg\n",
    "        )\n",
    "        \n",
    "        print(\"\\n3. Saving ensemble submissions...\")\n",
    "        save_ensemble_submissions(ensemble_methods, test_ids, class_mapping)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in ensemble pipeline: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def create_final_submission():   \n",
    "    import glob\n",
    "    ensemble_files = glob.glob('ensemble_submission_*.csv')\n",
    "    \n",
    "    if len(ensemble_files) == 0:\n",
    "        print(\"No ensemble submission files found. Please run Cell 2 first.\")\n",
    "        return\n",
    "        \n",
    "    submissions = []\n",
    "    for file in ensemble_files[:3]:  \n",
    "        df = pd.read_csv(file)\n",
    "        submissions.append(df)\n",
    "    \n",
    "    if len(submissions) == 0:\n",
    "        print(\"No valid submission files to process.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nCreating weighted final submission...\")\n",
    "    \n",
    "    final_df = submissions[0].copy()\n",
    "    \n",
    "    final_df['MasterItemNo'] = submissions[0]['MasterItemNo']\n",
    "    \n",
    "    if len(submissions) > 1:\n",
    "        weights = [0.5, 0.3, 0.2][:len(submissions)]\n",
    "        weights = np.array(weights) / sum(weights)  \n",
    "        \n",
    "        all_reg_preds = np.array([sub['QtyShipped'].values for sub in submissions])\n",
    "        final_reg_preds = np.average(all_reg_preds, axis=0, weights=weights)\n",
    "        final_df['QtyShipped'] = np.maximum(final_reg_preds, 0)  \n",
    "    \n",
    "    final_df.to_csv('submission.csv', index=False)\n",
    "    \n",
    "    print(\"Final submission created!\")\n",
    "    print(f\"Shape: {final_df.shape}\")\n",
    "    print(f\"MasterItemNo unique values: {final_df['MasterItemNo'].nunique()}\")\n",
    "    print(f\"QtyShipped range: {final_df['QtyShipped'].min():.2f} to {final_df['QtyShipped'].max():.2f}\")\n",
    "    \n",
    "    print(\"\\nSubmission preview:\")\n",
    "    print(final_df.head(10))\n",
    "    \n",
    "    print(\"Final submission saved as 'submission.csv'\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    main_train()\n",
    "    main_ensemble()\n",
    "    create_final_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42dbcca-1ba5-40ea-858c-f50bf7906006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74967a1a-92b4-4f72-8e5f-953420bfcef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
